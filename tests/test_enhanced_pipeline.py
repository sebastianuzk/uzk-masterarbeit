#!/usr/bin/env python3
"""
Test-Script f√ºr die erweiterte WiSo Scraper Pipeline
====================================================

Dieses Script testet alle Komponenten des erweiterten Scraper-Systems,
einschlie√ülich der neuen Enhancement-Features.
"""

import sys
import asyncio
import logging
from pathlib import Path
import pytest

# Projekt-Root zum Pfad hinzuf√ºgen
sys.path.insert(0, str(Path(__file__).parent))

# Setup Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


@pytest.mark.asyncio
async def test_enhanced_pipeline_small():
    """Test 0: Enhanced Pipeline mit kleinem Datenset (20 Seiten)"""
    print("\n" + "="*70)
    print("TEST 0: Enhanced Scraping Pipeline (Klein)")
    print("="*70)
    
    try:
        from src.scraper.crawler_scraper_pipeline import run_crawler_scraper_pipeline
        
        output_dir = Path("data/test_enhanced_small")
        
        print("Testing mit 20 Seiten und allen Enhancements aktiviert:")
        print("  ‚Ä¢ Intelligentes Caching")
        print("  ‚Ä¢ Content-Deduplizierung")
        print("  ‚Ä¢ Content-Bereinigung")
        print("  ‚Ä¢ Semantisches Chunking")
        print("  ‚Ä¢ Resilient Scraping")
        print("  ‚Ä¢ Metriken")
        print()
        
        stats = await run_crawler_scraper_pipeline(
            output_dir=output_dir,
            max_pages=20,
            crawl_delay=0.5,
            scrape_delay=0.5,
            concurrent_requests=5,
            organize_by_category=True,
            enable_caching=True,
            enable_deduplication=True,
            enable_content_cleaning=True
        )
        
        print("\n‚úì Pipeline erfolgreich ausgef√ºhrt")
        print(f"‚úì URLs entdeckt: {stats['results']['urls_discovered']}")
        print(f"‚úì URLs gescraped: {stats['results']['urls_scraped']}")
        print(f"‚úì Chunks erstellt: {stats['results']['total_chunks_created']}")
        print(f"‚úì Dokumente gespeichert: {stats['results']['total_documents_stored']}")
        print(f"‚úì Success Rate: {stats['metrics']['success_rate']:.1f}%")
        
        # Pr√ºfe ob Metriken-Files erstellt wurden
        metrics_file = output_dir / "scraper_metrics.json"
        cache_file = output_dir / "cache_statistics.json"
        
        if metrics_file.exists():
            print(f"‚úì Metriken exportiert: {metrics_file}")
        if cache_file.exists():
            print(f"‚úì Cache-Statistiken exportiert: {cache_file}")
        
        print("\n‚úÖ Enhanced Pipeline Test BESTANDEN")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Enhanced Pipeline Test FEHLGESCHLAGEN: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_vector_db():
    """Test 1: Vector-Datenbank √ºberpr√ºfen"""
    print("\n" + "="*70)
    print("TEST 1: Vector-Datenbank Status")
    print("="*70)
    
    try:
        import chromadb
        
        vector_db_path = Path('data/vector_db').resolve()
        print(f"‚úì Vector DB Pfad: {vector_db_path}")
        print(f"‚úì Existiert: {vector_db_path.exists()}")
        
        if not vector_db_path.exists():
            print("‚ùå Vector DB nicht gefunden! Pipeline zuerst ausf√ºhren.")
            return False
        
        client = chromadb.PersistentClient(path=str(vector_db_path))
        collections = client.list_collections()
        
        print(f"\n‚úì Collections gefunden: {len(collections)}")
        total_docs = 0
        for c in collections:
            count = c.count()
            total_docs += count
            print(f"  ‚Ä¢ {c.name}: {count} Dokumente")
        
        print(f"\n‚úì Dokumente insgesamt: {total_docs}")
        
        if total_docs == 0:
            print("‚ùå Keine Dokumente in der Datenbank!")
            return False
        
        print("\n‚úÖ Vector DB Test BESTANDEN")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Vector DB Test FEHLGESCHLAGEN: {e}")
        return False


def test_rag_tool():
    """Test 2: RAG Tool Funktionalit√§t"""
    print("\n" + "="*70)
    print("TEST 2: RAG Tool Funktionalit√§t")
    print("="*70)
    
    try:
        from src.tools.rag_tool import UniversityRAGTool
        
        tool = UniversityRAGTool()
        print("‚úì RAG Tool initialisiert")
        
        # Test-Anfragen
        test_queries = [
            ("Master Programme", "studium"),
            ("IT Support", "services"),
            ("Forschung", "forschung"),
        ]
        
        print("\n‚úì F√ºhre Test-Anfragen aus...")
        passed = 0
        
        for query, expected_category in test_queries:
            print(f"\n  Anfrage: '{query}'")
            result = tool._run(query)
            
            if "‚ùå" in result:
                print(f"    ‚ö†Ô∏è  Keine Ergebnisse (ben√∂tigt evtl. mehr Daten)")
            elif expected_category in result.lower() or len(result) > 100:
                print(f"    ‚úì Relevante Ergebnisse erhalten ({len(result)} Zeichen)")
                passed += 1
            else:
                print(f"    ‚ö†Ô∏è  Unerwartetes Ergebnis")
        
        print(f"\n‚úì Bestanden: {passed}/{len(test_queries)} Anfragen")
        
        if passed > 0:
            print("\n‚úÖ RAG Tool Test BESTANDEN")
            return True
        else:
            print("\n‚ùå RAG Tool Test FEHLGESCHLAGEN - keine erfolgreichen Anfragen")
            return False
        
    except Exception as e:
        print(f"\n‚ùå RAG Tool Test FEHLGESCHLAGEN: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_files():
    """Test 3: Gescrapte Datendateien √ºberpr√ºfen"""
    print("\n" + "="*70)
    print("TEST 3: Gescrapte Datendateien")
    print("="*70)
    
    try:
        import json
        
        files = {
            "scraped_data": Path("src/scraper/data_analysis/scraped_data.json"),
            "discovered_urls": Path("src/scraper/data_analysis/discovered_urls.json"),
        }
        
        for name, filepath in files.items():
            print(f"\n‚úì Pr√ºfe {name}...")
            
            if not filepath.exists():
                print(f"  ‚ö†Ô∏è  Datei nicht gefunden: {filepath}")
                continue
            
            with open(filepath) as f:
                data = json.load(f)
            
            if name == "scraped_data":
                count = len(data)
                success = sum(1 for d in data if d.get('success', False))
                print(f"  ‚úì Seiten insgesamt: {count}")
                print(f"  ‚úì Erfolgreich: {success} ({success/count*100:.1f}%)")
            elif name == "discovered_urls":
                count = data.get('total_urls', len(data.get('urls', [])))
                print(f"  ‚úì URLs gefunden: {count}")
        
        print("\n‚úÖ Datendateien Test BESTANDEN")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Datendateien Test FEHLGESCHLAGEN: {e}")
        return False


def test_categorization():
    """Test 4: URL-Kategorisierung"""
    print("\n" + "="*70)
    print("TEST 4: URL-Kategorisierungslogik")
    print("="*70)
    
    try:
        from src.scraper.crawler_scraper_pipeline import categorize_url
        
        test_urls = {
            "https://wiso.uni-koeln.de/de/studium/bachelor": "studium",
            "https://wiso.uni-koeln.de/de/forschung": "forschung",
            "https://wiso.uni-koeln.de/de/services/it": "services",
            "https://wiso.uni-koeln.de/de/fakultaet/dekanat": "fakultaet",
        }
        
        passed = 0
        for url, expected in test_urls.items():
            result = categorize_url(url)
            if result == expected:
                print(f"  ‚úì {url} ‚Üí {result}")
                passed += 1
            else:
                print(f"  ‚úó {url} ‚Üí {result} (erwartet {expected})")
        
        print(f"\n‚úì Bestanden: {passed}/{len(test_urls)} Kategorisierungen")
        
        if passed == len(test_urls):
            print("\n‚úÖ Kategorisierungs-Test BESTANDEN")
            return True
        else:
            print("\n‚ö†Ô∏è  Kategorisierungs-Test TEILWEISE")
            return True  # Nicht kritisch
        
    except Exception as e:
        print(f"\n‚ùå Kategorisierungs-Test FEHLGESCHLAGEN: {e}")
        return False


def run_all_tests():
    """Alle Tests ausf√ºhren und Ergebnisse berichten"""
    print("\n" + "="*70)
    print("üß™ WiSo Scraper Erweiterte Pipeline Test-Suite")
    print("="*70)
    
    # Async Test zuerst
    print("\nF√ºhre Enhanced Pipeline Test aus...")
    try:
        enhanced_passed = asyncio.run(test_enhanced_pipeline_small())
    except Exception as e:
        print(f"‚ùå Enhanced Pipeline Test abgest√ºrzt: {e}")
        enhanced_passed = False
    
    # Sync Tests
    tests = [
        ("Vector-Datenbank", test_vector_db),
        ("RAG Tool", test_rag_tool),
        ("Datendateien", test_data_files),
        ("Kategorisierung", test_categorization),
    ]
    
    results = [("Enhanced Pipeline (Klein)", enhanced_passed)]
    
    for name, test_func in tests:
        try:
            passed = test_func()
            results.append((name, passed))
        except Exception as e:
            print(f"\n‚ùå Test '{name}' abgest√ºrzt: {e}")
            results.append((name, False))
    
    # Zusammenfassung
    print("\n" + "="*70)
    print("üìä Test-Zusammenfassung")
    print("="*70)
    
    passed_count = sum(1 for _, passed in results if passed)
    total_count = len(results)
    
    for name, passed in results:
        status = "‚úÖ BESTANDEN" if passed else "‚ùå FEHLGESCHLAGEN"
        print(f"{status:15} - {name}")
    
    print("\n" + "-"*70)
    print(f"Insgesamt: {passed_count}/{total_count} Tests bestanden")
    
    if passed_count == total_count:
        print("\nüéâ Alle Tests BESTANDEN! System ist bereit.")
        return 0
    elif passed_count > 0:
        print(f"\n‚ö†Ô∏è  {total_count - passed_count} Test(s) fehlgeschlagen.")
        return 1
    else:
        print("\n‚ùå Alle Tests FEHLGESCHLAGEN! System-Setup √ºberpr√ºfen.")
        return 2


if __name__ == "__main__":
    sys.exit(run_all_tests())
